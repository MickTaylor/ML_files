{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Example with `tflearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Michelle Lochner</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>(With lots of help from Boris Leistedt, Gilles Louppe and Christopher Bonnett)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to use `tflearn` (http://tflearn.org/) to create your own convolutional neural network (CNN) to run on your own dataset. \n",
    "\n",
    "This is an amalgamation of the  examples on Keras (https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py), the `tflearn` example (https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_mnist.py) with some added visualisation from https://github.com/julienr/ipynb_playground/blob/master/keras/convmnist/keras_cnn_mnist.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A super brief introduction to CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Disclaimer</b>: I am not an expert on the theory of CNNs. None of the information below is guaranteed to be accurate. I will just add practical points, that I have figured out, to better understand how to make this algorithm work for your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These Stanford course notes http://cs231n.github.io/convolutional-networks/ are amazing, it doesn't take long to go through them and get a pretty good understanding of CNNs (and other neural nets too). I'll add a couple of images with descriptions from those notes to give you an idea of CNNs. Another really well-written resource is http://colah.github.io/posts/2014-07-Conv-Nets-Modular/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Structure of neural networks</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic structure of any neural network, which were invented to attempt to emulate the connections found in the brain. Essentially it learns a non-linear transformation which converts input to output. Like any machine learning algorithm, you train it on some training data with known output. The hidden layers are made up of \"neurons\", which connect to every feature of the input, performing said non-linear transforms. Each neuron has a weight and these are learned from training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"neural_net2.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>What makes convolutional neural networks different?</b>\n",
    "\n",
    "It's usually quite rare to get much benefit from making neural networks more than one or two layers deep. CNNs are different because they can be dozens or even hundreds of layers deep.\n",
    "\n",
    "CNNs are truly designed to work with images, it's built into their architecture (although it is possible to use them successfully on other types of features). Neurons (which actually tend to be called nodes or filters in CNN literature) now have volume instead of just being points. This is because they are designed to look at small pieces of the input image (this division of labour makes it possible to go so deep) within their little volume, called a \"receptive field\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"neural_net2a.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"convolution\" part of convolutional neural networks refers to a particular type of layer, a convolutional layer, which is made up of filters that, when training, <i>slide</i> around the image, filtering bits of it (which is a convolution in effect) to see what filters get activated by what parts of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing I'll talk about is the fact that CNNs are not purely made of convolutional layers. There are several types, the most common of which are: fully connected or dense layers (\"standard\" neural network layers), convolutional layers, activation layers (which does the \"what filters are activated by what\" bit) such as \"ReLu\" layer, pooling layers (pool filters from previous layers and downsample) and dropout layers (which drop some of the weights to prevent overfitting). The best thing is to read the notes on these things. The most difficult part of deep learning is figuring out what combinations of layers to use, as there aren't any hard and fast rules. Here's an example network architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"convnet.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tflearn to build a CNN for the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now build a CNN for the standard MNIST dataset, which is a dataset of thousands of small images of hand-written digits. The network will learn (very effectively) how to do handwriting recognition on these digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: `tflearn` will run much faster if you install with an nvidia GPU.\n",
    "\n",
    "Note2: There are several packages for deep learning, most based on tensorflow or theano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n",
    "To run this notebook, tensorflow and tflearn must both be installed.\n",
    "\n",
    "Run:<br>\n",
    "`pip3 install tensorflow --user`<br>\n",
    "`pip3 install tflearn --user`<br>\n",
    "\n",
    "You can also use `pip3 install tensorflow-gpu --user` if your computer has a graphics card to speed up the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# Data loading and preprocessing\n",
    "import tflearn.datasets.mnist as mnist\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and split into a training dataset and a test dataset for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X, Y, testX, testY = mnist.load_data(one_hot=True)\n",
    "X = X.reshape([-1, 28, 28, 1])\n",
    "testX = testX.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Network architecture</b>\n",
    "\n",
    "We add two convolution layers, both activated with a standard activation layer, followed by pooling and some dropout to reduce overfitting.\n",
    "\n",
    "The final \"softmax\" activation layer is what brings all the filters together to get a final classification, hence its output dimensions will always be the number of classes.\n",
    "\n",
    "When compiling the model, you have to choose a loss function (usually categorical_crossentropy for classification, mean_squared_error for regression) and an optimizer, for which adam works quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/michelle/anaconda2/envs/ml/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/michelle/anaconda2/envs/ml/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "network = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")\n",
    "network = max_pool_2d(network, 2)\n",
    "network = local_response_normalization(network)\n",
    "network = fully_connected(network, 128, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 256, activation='tanh')\n",
    "network = dropout(network, 0.8)\n",
    "network = fully_connected(network, 10, activation='softmax')\n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,\n",
    "                     loss='categorical_crossentropy', name='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Training the model</b>\n",
    "\n",
    "This can take quite a long time (even for the reduced dataset). As the network runs, it will print the loss function value (which should keep going down) and the accuracy for the training set. It will also then validate on the validation set after each epoch and print the loss and accuracy there. If the training accuracy is much higher than the validation accuracy, you are overfitting. To reduce overfitting you can decrease the complexity of the network, increase the size of your training set (such as using data augmentation) or (simple possible fix) increase the amount of dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1719  | total loss: \u001b[1m\u001b[32m0.30460\u001b[0m\u001b[0m | time: 131.169s\n",
      "| Adam | epoch: 002 | loss: 0.30460 - acc: 0.9356 -- iter: 54976/55000\n",
      "Training Step: 1720  | total loss: \u001b[1m\u001b[32m0.29547\u001b[0m\u001b[0m | time: 134.311s\n",
      "| Adam | epoch: 002 | loss: 0.29547 - acc: 0.9374 | val_loss: 0.10954 - val_acc: 0.9704 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=2,\n",
    "           validation_set=({'input': testX}, {'target': testY}),\n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interactive plot will (more or less) let you step through and see the CNN's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "probs = model.predict(testX[:N])\n",
    "pred_labels = np.argmax(probs, axis=1)\n",
    "\n",
    "def plot_image(ind):\n",
    "    img = testX[ind]\n",
    "    pred_label = pred_labels[ind]\n",
    "    plt.imshow(img[:,:,0])\n",
    "    plt.xlabel('Predicted label %d' %pred_label)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='both',bottom='off', left='off',labelbottom='off', labelleft='off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e2338f9f784586bf4740459f461bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=50, description='ind'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_image(ind)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "interact(plot_image, ind=(0,100),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
